<!DOCTYPE html>
<html>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" type="text/css" href="style.css">
    <title>Temario</title>
  </head>
  <body>
    
    <h1>Probabilidad y Estadistica</h1>
    <a href="https://app.dataquest.io/profile/230110322">Link de curso dataquest</a>
    <h2>Temario</h2>
    <h2>Tema1=Estadística descriptiva.</h2>
    <img src="imagenes/images.jpeg" alt="imagen representativa" width="400" height="300">
    
    <h3>
        1.1 Conceptos básicos de estadística</h3>
    <ul>
        <li>Definición: La estadística es una ciencia que recolecta, organiza, analiza e interpreta datos con el propósito de obtener información útil que nos permite describir, comprender y hacer conclusiones sobre fenómenos y eventos.</li>
        <li>Teoría de decisión: La teoría de decisión es un campo de la estadística que se enfoca en tomar buenas decisiones bajo incertidumbre, las cuales proporcionan un marco para analizar y evaluar diferentes opciones y tomar la mejor solución de los objetivos, la información disponible y las consecuencias potenciales.</li>
        <li>Población: En estadística, una población se refiere al conjunto completo de personas, objetos o eventos, etc. que se desea estudiar. La población puede ser finita o infinita cuando es imposible contar todos los elementos.</li>
        <li>Muestra aleatoria: Una muestra aleatoria es un subconjunto de elementos seleccionados al azar de una población.</li>
        <li>Parámetros aleatorios: Los parámetros aleatorios son características o medidas de la media, la varianza, la proporción, etc, que describen una población o distribución de probabilidad.</li>
      </ul>
    <h3>1.2 Descripción de datos</h3>
    <ul>
        <li>Datos no agrupados: Son los datos individuales sin ninguna organización previa.</li>
        <li>Datos agrupados: Son los datos que se han organizado en clases, lo que permite resumir y analizar la información de manera más eficiente.</li> 
        <li>Frecuencia de clase: La frecuencia de clase es el número de elementos o datos que existen dentro de cada intervalo o clase en un conjunto de datos agrupados.</li>
        <li>Frecuencia relativa: La frecuencia relativa es el porcentaje de elementos que se encuentran en cada clase o intervalo con respecto al total de datos. Se calcula dividiendo la frecuencia de cada clase por el número total de datos.</li>
        <li>Punto medio: El punto medio de una clase es el valor que se encuentra en el centro del intervalo. Se calcula como la media aritmética entre el límite inferior y el límite superior de la clase.</li>
        <li>Límites:
            <li>Límite inferior: Es el valor más bajo del intervalo de clase.</li>
            <li>Límite superior: Es el valor más alto del intervalo de clase.</li>
      </ul>
      <img src="imagenes/Resumen-de-datos--simplificando-la-complejidad-con-analisis-descriptivo--Descripci-n-general.webp" alt="" width="400" height="300">
    <h3>1.3 Medidas de tendencia central</h3>
    <ul>
        <li>Media aritmética: Es el promedio de un conjunto de datos obtenidos, sumando todos los valores y dividiendo entre el número total de datos.</li>
        <li>Media geométrica: Es una media que se calcula multiplicando todos los valores y extraer la raíz del número total de datos. Es útil para datos con proporciones o porcentajes.</li>
        <li>Media ponderada: Es una media que tiene en cuenta la importancia relativa de cada valor a través de pesos o factores de ponderación.</li>
        <li>Mediana: Es el valor central de un conjunto de datos ordenados de menor a mayor. Divide al conjunto en dos partes iguales.</li>
        <li>Moda: Es el valor que aparece con mayor frecuencia en un conjunto de datos.</li>
        <li>Medidas de Dispersión</li>
        <li>Varianza: Es una medida que indica cuánto se alejan en promedio los valores de la media. Se calcula como el promedio de los cuadrados de las desviaciones de cada valor respecto a la media.</li>
        <li>Desviación estándar: Es la raíz cuadrada de la varianza que indica cuánto se desvían en promedio los valores respecto a la media.</li>
        <li>Desviación media: Es el promedio de las diferencias absolutas entre cada valor y la media.</li>
        <li>Desviación mediana: Es el promedio de las diferencias absolutas entre cada valor y la mediana.</li>
        <li>Rango: Es la diferencia entre el valor más alto y el más bajo de un conjunto de datos.</li>
      </ul>
    <h3>1.4 Parámetros para datos agrupados.</h3>
    <ul>
        <li>Los parámetros nos permiten describir y resumir la información contenida en un conjunto de datos agrupados en intervalos o clases. Estos son fundamentales para realizar un análisis estadístico y visualizaciones gráficas, como histogramas y diagramas de caja.</li>
    </ul>
    <h3>1.5 Distribución de frecuencias.</h3>
    <ul>
        <li>La distribución de frecuencia es una forma de organizar y presentar un conjunto de datos, agrupándolos en intervalos o clases y mostrando la frecuencia o el número de elementos que existen en cada uno de esos intervalos.</li>
    </ul>
   <h3>1.6 Técnicas de agrupación de datos.</h3> 
   <ul> 
    <li>Las técnicas de agrupación de datos, también conocidas como técnicas de clustering, son métodos utilizados para organizar y clasificar un conjunto de datos en grupos.</li> 
    <li>Clustering jerárquico: Es un método que construye una jerarquía de clusters, en la que los elementos se van agrupando de manera sucesiva.</li> 
    <li>Clustering basado en densidad: Identifica clusters en función de la densidad de los datos, agrupando aquellos elementos que se encuentran en regiones de alta densidad y separándolos de aquellos que se encuentran en regiones de baja densidad.</li> 
    <li>Clustering de partición: Divide el conjunto de datos en un número predefinido de clusters, de tal manera que cada elemento pertenece a un único cluster.</li> 
    <li>Clustering basado en modelos: Asume que los datos provienen de una mezcla de distribuciones de probabilidad y utiliza métodos de estimación de máxima verosimilitud para identificar los parámetros de dichas distribuciones.</li> 
  </ul> 
  <img src="imagenes/images-2.jpeg" alt=""> 
  <h3>1.7 Técnicas de muestreo.</h3> 
  <ul> 
    <li>Las técnicas de muestreo son métodos utilizados para seleccionar una parte representativa de una población, con el objetivo de estudiar y obtener conclusiones sobre dicha población a partir de la información recolectada en la muestra.</li> 
    <li>Muestreo aleatorio simple: Cada elemento de la población tiene la misma probabilidad de ser seleccionado para la muestra. Se realiza de manera totalmente aleatoria, sin seguir ningún patrón.</li> 
    <li>Muestreo aleatorio estratificado: La población se divide en subgrupos (estratos) homogéneos, y luego se selecciona una muestra aleatoria de cada estrato, de manera proporcional o desproporcional.</li> 
    <li>Muestreo sistemático: Se selecciona un elemento de la población al azar y luego se eligen los siguientes elementos a intervalos regulares.</li> <li>Muestreo por cuotas: Se establecen cuotas o proporciones de determinadas características en la muestra, que deben reflejar las mismas proporciones existentes en la población.</li> 
  </ul> 
  <h3>1.8 Histogramas</h3> 
  <ul> 
    <li>Un histograma es una representación gráfica que muestra la distribución de frecuencia de una variable numérica. Consiste en un conjunto de barras rectangulares donde: El eje horizontal representa los rangos o intervalos de valores de la variable. El eje vertical representa la frecuencia o cantidad de datos que caen en cada rango. La altura de cada barra indica cuántos datos hay en ese intervalo. </li> 
  </ul>
    <img src="imagenes/Unknown" alt="">
    <p>El siguiente repositorio es una representacion de lo que se puede realizar en el tema 1</p>
    <a href="imagenes/code.html">HTML</a>
    <h2>Tema2 = Fundamentos de la Teoría de Probabilidad.</h2>
   
    <h3>2.1 Técnicas de Conteo</h3>
    <ul>
      <li>Las técnicas de conteo son un conjunto de métodos matemáticos utilizados para calcular el número de formas en que se puede realizar una determinada selección de elementos dentro de un conjunto. Estas técnicas se utilizan comúnmente en problemas de probabilidad y combinatoria.</li>
    </ul>
    <img src="imagenes/Te%CC%81cnicas+de+conteo+Contenido+tema%CC%81tico+Principio+de+la+multiplicacio%CC%81n.jpg" alt="" width="400" height="300">
    <h3>2.1.1 Principio aditivo.</h3>
    <ul>
      <li> El Principio Aditivo, también conocido como Regla de la Suma o Principio de la Adición, es uno de los principios fundamentales en las técnicas de conteo, el  principio Aditivo establece que si tenemos dos o más eventos mutuamente excluyentes (es decir, que no pueden ocurrir al mismo tiempo), entonces el número total de formas en que puede ocurrir alguno de esos eventos es la suma de los números de formas en que puede ocurrir cada evento por separado.</li>
    </ul>
    <h3>2.1.2 Principio multiplicativo.</h3>
    <ul>
      <li>El Principio Multiplicativo, también conocido como Regla del Producto o Principio Fundamental del Conteo, es otro de los principios fundamentales en las técnicas de conteo.
        El Principio Multiplicativo establece que si una tarea se puede realizar de n maneras diferentes y luego otra tarea se puede realizar de m maneras diferentes, independientemente de la primera tarea, entonces la secuencia completa de ambas tareas se puede realizar de n × m maneras diferentes.</li>
    </ul>
    <h3>2.1.3 Notación Factorial.</h3>
    <ul>
      <li>la notación factorial es una forma concisa y poderosa de representar y trabajar con productos de números naturales consecutivos, siendo una herramienta fundamental en el campo de la combinatoria y la probabilidad.</li>
    </ul>
    <h3>2.1.4 Permutaciones.</h3>
    <ul>
      <li>Las permutaciones se refieren a la forma de ordenar o arreglar un conjunto de elementos. En otras palabras, las permutaciones representan el número de formas en que se pueden organizar o disponer los elementos de un conjunto.</li>
    </ul>
    <h3>2.1.5 Combinaciones.</h3>
    <ul>
      <li>Las combinaciones se refieren a la forma de seleccionar un subconjunto de elementos de un conjunto, sin tener en cuenta el orden en que se seleccionan los elementos.</li>
    </ul>
    <h3>2.1.6 Diagrama de Árbol.</h3>
    <li>Un diagrama de árbol es una herramienta gráfica utilizada para representar visualmente las posibles secuencias de eventos o resultados en un problema de probabilidad o conteo.</li>
    <h4>Estructura de un diagrama de árbol</h4>
   <ul>
    <li><strong>Nodos:</strong> Representan los eventos o resultados posibles.</li>
    <li><strong>Ramas:</strong> Representan las transiciones entre los eventos o resultados.</li>
   </ul>
   <h4>Características principales</h4>
   <ul>
    <li><strong>Ramificación:</strong> Cada nodo puede tener una o más ramas que representan los posibles resultados.</li>
    <li><strong>Jerarquía:</strong> Los nodos se organizan de arriba hacia abajo, mostrando la secuencia de eventos.</li>
    <li><strong>Probabilidades:</strong> Cada rama puede llevar asociada una probabilidad de ocurrencia.</li>
   </ul>
   <img src="imagenes/diagrama-de-arbol-ejemplo-img002.jpg.webp" alt="" width="400" height="300">
    <h3>2.1.7 Teorema del Binomio.</h3>
    <ul>
      <li>El Teorema del Binomio es un importante resultado matemático que permite calcular de manera sencilla el desarrollo de una expresión binomial elevada a una potencia.</li>
    </ul>
    <h3>2.2 Teoría elemental de probabilidad.</h3>
    <ul>
      <li>La Teoría Elemental de la Probabilidad es la rama de las matemáticas que estudia los fundamentos y conceptos básicos del cálculo de probabilidades</li>
    </ul>
    <h3>2.3 Probabilidad de Eventos.</h3>
    <ul>
  
      <li>Definición de espacio muestral = El espacio muestral es un concepto fundamental en la Teoría Elemental de la Probabilidad, ya que define el marco en el cual se realizan los cálculos de probabilidad para los diferentes eventos que pueden ocurrir en un experimento aleatorio.</li>
      <li>Definición de evento = Los eventos son la base para calcular las probabilidades en un experimento aleatorio. Mediante la definición y manipulación de eventos, se pueden realizar los cálculos probabilísticos necesarios para resolver problemas y aplicaciones en diversas áreas.</li>
      <li>Simbología = La simbología permite una representación concisa y eficiente de los conceptos y operaciones de la Teoría Elemental de la Probabilidad, facilitando su aplicación y manipulación en la resolución de problemas.</li>
      <li>Unión = La unión de eventos es una de las operaciones fundamentales en la Teoría Elemental de la Probabilidad, y se utiliza para calcular probabilidades cuando se requiere que ocurra al menos uno de los eventos.</li>
      <li>Intersección = La intersección de eventos es una operación fundamental en la Teoría Elemental de la Probabilidad, y se utiliza para calcular probabilidades cuando se requiere que ocurran simultáneamente dos eventos.</li>
      <li>Diagramas de Venn = Los diagramas de Venn son una representación gráfica muy útil para visualizar y comprender las operaciones y relaciones entre conjuntos, particularmente en el contexto de la Teoría Elemental de la Probabilidad.</li>
    </ul>
    <img src="imagenes/Captura-de-Pantalla-2023-09-14-a-las-9.24.49.png" alt="" width="400" height="300">
    <h3>2.4 Probabilidad con Técnicas de Conteo.</h3>
    <ul>
      <li>Axiomas = Los axiomas de la teoría de la probabilidad son los principios fundamentales que rigen el cálculo y la interpretación de las probabilidades. Estos axiomas fueron establecidos por el matemático ruso Andréi Kolmogórov en 1933. </li>
      <li>Teoremas = Los teoremas son un conjunto con los axiomas y las técnicas de conteo, constituyen las herramientas fundamentales para el análisis y cálculo de probabilidades en diversos problemas y aplicaciones.</li>
    </ul>
    <h3>2.5 Probabilidad condicional.</h3>
    <ul>
      <li>La probabilidad condicional es una herramienta fundamental para modelar y cuantificar la dependencia entre eventos en la teoría de la probabilidad.</li>
      <li>Dependiente = En probabilidad, cuando dos eventos A y B son dependientes, significa que el resultado de uno de ellos afecta la probabilidad del otro. En otras palabras, el conocimiento de que uno de los eventos ha ocurrido modifica la probabilidad del otro evento.
        La dependencia entre eventos se expresa a través de la probabilidad condicional. Si los eventos A y B son dependientes, entonces la probabilidad de A dado B (P(A|B)) es diferente a la probabilidad de A sin tener en cuenta B (P(A)).</li>
      <li>Independiente = Cuando dos eventos A y B son independientes, significa que el resultado de uno de ellos no afecta la probabilidad del otro. En otras palabras, el conocimiento de que uno de los eventos ha ocurrido no modifica la probabilidad del otro evento.</li>
    </ul>
    <h3>2.6 Ley multiplicativa.</h3>
    <ul>
      <li>La ley multiplicativa en probabilidad es una regla que relaciona la probabilidad conjunta de dos eventos con sus respectivas probabilidades individuales y la probabilidad condicional.
        La ley multiplicativa es muy útil para calcular probabilidades conjuntas a partir de probabilidades individuales y condicionales. Además, se utiliza como base para el Teorema de Bayes, que permite actualizar probabilidades a partir de nueva información.
      </li>

    </ul>
    <h3>2.7 Eventos independientes.</h3>
    <ul>
      <li>Regla de Bayes = La Regla de Bayes es un teorema fundamental en probabilidad y estadística que permite actualizar la probabilidad de una hipótesis o evento A, a la luz de nueva evidencia o información B.</li>
    </ul>
   
<img src="imagenes/teorema-de-bayes-fo%CC%81rmula-simple.jpg" alt="">
<p>En este html se realizan ejercicios para la comprencion del tema 2</p>

<a href="imagenes/Ejercicios-2.html">HTML</a>
  <h2>Tema3=Variables Aleatorias</h2> 
  <img src="imagenes/Unknown-4" alt="">
    <h3>3.1 Variables aleatorias discretas:</h3>
    <ul>
      <li>Las variables aleatorias discretas son aquellas que pueden tomar únicamente valores separados o puntuales dentro de un conjunto finito o numerable.</li>
    </ul>
    <img src="imagenes/Captura%20de%20pantalla%202024-07-02%20a%20la(s)%209.15.56.png" alt="" width="200" height="100">
    <p>Este es un video que explica el subtema de variables discretas</p><a href="https://www.canva.com/design/DAGJ0JN2kR0/YbMN3NtCqGq67xNaMu8Mhg/view?utm_content=DAGJ0JN2kR0&utm_campaign=designshare&utm_medium=link&utm_source=recording_view">Miralo aqui</a>
    <h3>3.1.1 Distribución de probabilidad en forma  general.</h3>
    <ul>
      <li>la distribución de probabilidad es una función matemática que describe la probabilidad de que una variable aleatoria tome determinados valores o se encuentre en ciertos intervalos</li>
    </ul>
    <img src="imagenes/Captura%20de%20pantalla%202024-07-02%20a%20la(s)%209.18.24.png" alt="" width="400" height="300">
    <h3>3.1.2 Valor esperado</h3>
    <ul>
      <li>El valor esperado, también conocido como esperanza matemática o media, es un concepto fundamental en la teoría de probabilidad y estadística. Representa el valor promedio que se espera obtener al observar muchas realizaciones de una variable aleatoria.</li>
    </ul>
    <img src="imagenes/Captura%20de%20pantalla%202024-07-02%20a%20la(s)%209.29.22.png" alt="" width="400" height="100">
    <h3>3.1.3 Variancia, desviación estándar. </h3>
    <ul>
      <li>La varianza es una medida de dispersión de una variable aleatoria X. Específicamente, la varianza mide cuánto se dispersan o se alejan los valores de X de su valor esperado o media (μ).</li>
    <li>La desviación estándar es una medida de dispersión que está íntimamente relacionada con la varianza. Específicamente, la desviación estándar se define como la raíz cuadrada positiva de la varianza.</li>
    </ul>
    <img src="imagenes/Captura%20de%20pantalla%202024-07-02%20a%20la(s)%209.22.18.png" alt="" width="400" height="100">
    <h3>3.1.4 Función acumulada.</h3>
    <ul>
      <li>La función de distribución acumulada, denotada como F(x), es una función fundamental en la teoría de probabilidad y estadística.
        La función de distribución acumulada de una variable aleatoria X se define como la probabilidad de que la variable X tome un valor menor o igual a x:
        La función de distribución acumulada proporciona información valiosa sobre el comportamiento de la variable aleatoria X. Permite calcular probabilidades, construir intervalos de confianza, realizar pruebas de hipótesis, entre otras aplicaciones importantes</li>
    </ul>
    <img src="imagenes/Captura%20de%20pantalla%202024-07-02%20a%20la(s)%209.25.19.png" alt="" width="400" height="200">
    <h3>3.2 Variables aleatorias Continuas:</h3>
    <ul>
      <li>Las variables aleatorias continuas son aquellas que pueden tomar cualquier valor dentro de un intervalo. A diferencia de las variables aleatorias discretas, que toman valores separados, las variables continuas pueden asumir una infinidad de valores.
        las variables aleatorias continuas se caracterizan por tener una función de densidad de probabilidad que describe su comportamiento, y una función de distribución acumulada que permite calcular probabilidades.
      </li>
    </ul>
    <p>Este es un video que explica el subtema de variables continuas</p><a href="https://www.canva.com/design/DAGJ0QXnssM/JjIRaAg2LRgcSUmhK4tEvA/view?utm_content=DAGJ0QXnssM&utm_campaign=designshare&utm_medium=link&utm_source=recording_view">Miralo aqui</a>
    <h3>3.2.1 Distribución de probabilidad en forma general.</h3> 
    <ul>
      <li>Una distribución de probabilidad es aquella que permite establecer toda la gama de resultados probables de ocurrir en un experimento determinado. Es decir, describe la probabilidad de que un evento se realice en el futuro.</li>
    </ul>
    <img src="imagenes/Captura%20de%20pantalla%202024-07-02%20a%20la(s)%209.27.50.png" alt="" width="400" height="
    200">
    <h3>3.2.2 Valor esperado</h3>
    <ul>
      <li>
        El valor esperado suele denominarse media o promedio "a largo plazo". Esto significa que a largo plazo de hacer un experimento una y otra vez, se esperaría este promedio</li>
    </ul>
    <img src="imagenes/Captura%20de%20pantalla%202024-07-02%20a%20la(s)%209.29.22.png" alt="" width="400" height="100">
    <h3>3.2.3 Variancia, desviación estándar.</h3>
    <ul>
      <li>La varianza y la desviación estándar indican si los valores se encuentran más o menos próximos a las medidas de posición. La desviación estándar es simplemente la raíz cuadrada positiva de la varianza.</li>
    </ul>
    <h3>3.2.4 Función acumulada.</h3>
    <ul>
      <li> La función de distribución acumulada (CDF) calcula la probabilidad acumulada de un valor dado de x. Utilice la CDF para determinar la probabilidad de que una observación aleatoria que se toma de la población sea menor que o igual a cierto valor.</li>
    </ul>
    <img src="imagenes/Captura%20de%20pantalla%202024-07-02%20a%20la(s)%209.31.18.png" alt="" width="400" height="200">
    <h3>3.2.5 Cálculos de probabilidad.</h3>
    <ul>
      <li>el cálculo de probabilidades es fundamental en el análisis estadístico y la toma de decisiones basada en datos. Las distribuciones de probabilidad proporcionan las herramientas necesarias para realizar estos cálculos de manera sistemática y rigurosa.</li>
    </ul>
<img src="imagenes/Unknown-3" alt="">
<h2>Tema 4= Distribuciones de Probabilidad.</h2>
<h3>4.1 Función de probabilidad</h3> 
<ul>
    <li>La función de probabilidad describe la probabilidad relativa de que una variable aleatoria continua X tome un determinado valor x. Se representa mediante la función de densidad de probabilidad f(x), la cual cumple ciertas propiedades como ser no negativa y tener un área total bajo la curva igual a 1.</li>
</ul> 
<img src="imagenes/continuous_distribution_def.png" alt="" width="400" height="200">
<h3>4.2 Distribución binomial</h3> 
<ul> 
    <li>La distribución binomial modela el número de éxitos en n ensayos independientes, donde cada ensayo tiene solo dos posibles resultados (éxito o fracaso) y la probabilidad de éxito es constante.</li> 
    <li>Sus parámetros son n (número de ensayos) y p (probabilidad de éxito en cada ensayo).</li> 
    <li>Fórmula de la Distribución binomial = <p style="text-align: center;"><em>\(  f(k; n, p) = \binom{n}{k} p^k (1-p)^{n-k} \)</em></p></li>
  </ul> 
  <p>En este video puedes ver un ejemplo de como resolverlo</p> <a href="https://www.canva.com/design/DAGKAoDV5uU/QE1KhR576kr2s5NEJrS65A/view?utm_content=DAGKAoDV5uU&utm_campaign=designshare&utm_medium=link&utm_source=recording_view">Miralo aqui</a>
<h3>4.3 Distribución la hipergeométrica</h3> 
<ul> 
    <li>La distribución hipergeométrica modela el número de éxitos en n extracciones sin reemplazamiento de una población finita que contiene N elementos, de los cuales M son "éxitos" y N-M son "fracasos".</li> 
    <li>Sus parámetros son N (tamaño de la población), M (número de "éxitos" en la población) y n (número de extracciones).</li> 
    <li>Fórmula de la Distribución hipergeométrica = <p style="text-align: center;"><em>\(  f(k; N, n, K) = \frac{\binom{K}{k}\binom{N-K}{n-k}}{\binom{N}{n}} \)</em></p> </li>
  </ul> 
<h3>4.4 Distribución de Poisson</h3> 
<ul> 
    <li>La distribución de Poisson modela el número de eventos ocurridos en un intervalo de tiempo o espacio, cuando estos eventos ocurren de forma independiente y a una tasa constante.</li> 
    <li>Su único parámetro es λ, que representa la tasa media de ocurrencia de los eventos.</li> 
    <li>Fórmula de la Distribución Poisson =  <p style="text-align: center;"><em>\(  f(k;\lambda) = \frac{e^{-\lambda}\lambda^k}{k!} \)</em></p></li>
  </ul> 

<img src="imagenes/images.png" alt="" width="400" height="200">
<h3>4.5 Distribución normal</h3> 
<ul> 
    <li>La distribución normal, también conocida como distribución gaussiana, es una de las distribuciones de probabilidad más importantes y ampliamente utilizada.</li> 
    <li>Se caracteriza por ser simétrica, unimodal y estar completamente determinada por sus dos parámetros: la media μ y la desviación estándar σ.</li> 
    <li>Fórmula de la Distribución Poisson =  <p style="text-align: center;"><em>\(  f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x - \mu)^2}{2\sigma^2}} \)</em></p></li>
  </ul>

<h3>4.6 Distribución T-student</h3> 
<ul> 
    <li>La distribución T-student es una familia de distribuciones de probabilidad que se utiliza cuando se trabaja con muestras pequeñas y la varianza poblacional es desconocida.</li> 
    <li>Está parametrizada por un único parámetro, que es el número de grados de libertad, y se aproxima a la distribución normal a medida que los grados de libertad aumentan.</li> 
</ul> 
<img src="imagenes/Student_densite_best.JPG" alt="" width="400" height="200">
<h3>4.7 Distribución Chi cuadrada</h3> 
<ul> 
    <li>La distribución Chi cuadrada se utiliza para modelar la suma de los cuadrados de variables aleatorias normales independientes estandarizadas.</li> 
    <li>Está parametrizada por un único parámetro, que es el número de grados de libertad, y tiene diversas aplicaciones en estadística, como en pruebas de hipótesis y cálculo de intervalos de confianza.</li> 
</ul> 
<h3>4.8 Distribución F</h3>
<ul> 
    <li>La distribución F, también conocida como distribución de Snedecor-Fisher, es una distribución de probabilidad continua que surge al considerar el cociente de dos variables aleatorias independientes que siguen una distribución Chi cuadrada.</li> 
    <li>Está parametrizada por dos números de grados de libertad, y tiene aplicaciones en el análisis de varianza (ANOVA) y otros procedimientos estadísticos.</li> 
</ul>


<h2>Tema5 = Regresión lineal</h2> 
<h3>5.1 Regresión y correlación</h3> 
<ul>
  <li>
    <p>Regresión:
      La regresión es una técnica estadística que se utiliza para modelar y analizar la relación entre una variable dependiente (o de respuesta) y una o más variables independientes (o predictoras). El objetivo de la regresión es encontrar la ecuación matemática que mejor describe la relación entre las variables. Los tipos más comunes de regresión son:
      Regresión lineal: Busca una relación lineal entre las variables.
      Regresión logística: Utilizada cuando la variable dependiente es categórica.
      Regresión múltiple: Usa múltiples variables independientes para predecir una variable dependiente.
      Correlación:
      La correlación mide la fuerza y la dirección de la relación lineal entre dos variables. El coeficiente de correlación, denotado por "r", varía entre -1 y 1:
      r = 1 indica una correlación positiva perfecta
      r = -1 indica una correlación negativa perfecta
      r = 0 indica que no hay relación lineal entre las variables</p>
  </li>
</ul>
<img src="imagenes/Estadistica-UNI5-011.jpg" alt="" width="400" height="300">
<h3>5.1.1 Diagrama de dispersión</h3> 
<p>Un diagrama de dispersión es una representación gráfica que muestra la relación entre dos variables. Cada punto en el gráfico representa un par de valores de las variables, lo que permite visualizar la posible asociación entre ellas.</p>
<img src="imagenes/images-2.png" alt="" width="400" height="300">
<h3>5.1.2 Regresión lineal simple</h3> 
<p>La regresión lineal simple es una técnica estadística que permite establecer una relación lineal entre una variable dependiente y una variable independiente. El objetivo es encontrar la ecuación de la recta que mejor se ajuste a los datos.</p> 
<h3>5.1.3 Correlación</h3>
<p>La correlación es una medida estadística que indica la fuerza y la dirección de la relación lineal entre dos variables. El coeficiente de correlación, que varía entre -1 y 1, permite cuantificar el grado de asociación entre las variables.</p> 
<img src="imagenes/images-3.png" alt="" width="400" height="">
<h3>5.1.4 Determinación y análisis de los coeficientes de correlación y de determinación</h3> 
<p>El coeficiente de determinación (R^2) es una medida que indica la proporción de la variabilidad de la variable dependiente que es explicada por la variable independiente en un modelo de regresión lineal. El análisis de estos coeficientes permite evaluar la calidad del ajuste y la significancia de la relación.</p> 
<h3>5.1.5 Distribución normal bidimensional</h3> 
<p>La distribución normal bidimensional es una extensión de la distribución normal univariante a dos variables aleatorias. Permite modelar la relación entre dos variables cuantitativas y es la base teórica de la regresión y correlación lineal.</p> 


</body>
</html>